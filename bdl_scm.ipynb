{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "bdl-scm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliceding0924/shichaoming_BDL/blob/alice/bdl_scm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CxI4uz2vcu-",
        "outputId": "66960fdc-4013-4717-d7e9-eb6f88d3dbea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG2kxpL4vugO",
        "outputId": "af44c31f-81c1-456f-ddd2-f65894f9b913"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:36.968387Z",
          "iopub.execute_input": "2021-09-27T11:44:36.969278Z",
          "iopub.status.idle": "2021-09-27T11:44:36.985209Z",
          "shell.execute_reply.started": "2021-09-27T11:44:36.969223Z",
          "shell.execute_reply": "2021-09-27T11:44:36.983784Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUvlphg4jJgs",
        "outputId": "6ec94a04-9b80-4d15-92d5-c9936509ef22"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "writer = SummaryWriter()\n",
        "sns.set()\n",
        "sns.set_style(\"dark\")\n",
        "sns.set_palette(\"muted\")\n",
        "sns.set_color_codes(\"muted\")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXnXz7EkwVi8"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "TEST_BATCH_SIZE = 5"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:45:12.768360Z",
          "iopub.execute_input": "2021-09-27T11:45:12.769177Z",
          "iopub.status.idle": "2021-09-27T11:45:12.819039Z",
          "shell.execute_reply.started": "2021-09-27T11:45:12.769136Z",
          "shell.execute_reply": "2021-09-27T11:45:12.818009Z"
        },
        "trusted": true,
        "id": "Snsd2MAfjJgy"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, file):\n",
        "        self.data = ('/content/drive/MyDrive/Colab Notebooks/Kather_5000_splitted')\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "dataset_train = MyDataset('/content/drive/MyDrive/Colab Notebooks/Kather_5000_splitted/train')\n",
        "train_loader = DataLoader(dataset_train, BATCH_SIZE, shuffle=True)\n",
        "\n",
        "dataset_test = MyDataset('/content/drive/MyDrive/Colab Notebooks/Kather_5000_splitted/val')\n",
        "test_loader = DataLoader(dataset_test, BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFyiZlihwaw9",
        "outputId": "58239cab-c8e3-417b-94ee-a7842e6b428f"
      },
      "source": [
        "TRAIN_SIZE = len(train_loader.dataset)\n",
        "print(TRAIN_SIZE)\n",
        "TEST_SIZE = len(test_loader.dataset)\n",
        "print(TEST_SIZE)\n",
        "NUM_BATCHES = len(train_loader)\n",
        "print(NUM_BATCHES)\n",
        "NUM_TEST_BATCHES = len(test_loader)\n",
        "print(NUM_TEST_BATCHES)\n",
        "\n",
        "# CLASSES = 10\n",
        "# TRAIN_EPOCHS = 20\n",
        "# SAMPLES = 2\n",
        "# TEST_SAMPLES = 10\n",
        "\n",
        "# assert (TRAIN_SIZE % BATCH_SIZE) == 0\n",
        "# assert (TEST_SIZE % TEST_BATCH_SIZE) == 0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n",
            "59\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:43:52.437440Z",
          "iopub.execute_input": "2021-09-27T11:43:52.437885Z",
          "iopub.status.idle": "2021-09-27T11:43:52.449985Z",
          "shell.execute_reply.started": "2021-09-27T11:43:52.437836Z",
          "shell.execute_reply": "2021-09-27T11:43:52.448888Z"
        },
        "trusted": true,
        "id": "YIR18VPcjJgz"
      },
      "source": [
        "class Gaussian(object):\n",
        "    def __init__(self, mu, rho):\n",
        "        super().__init__()\n",
        "        self.mu = mu\n",
        "        self.rho = rho\n",
        "        self.normal = torch.distributions.Normal(0,1)\n",
        "    \n",
        "    @property\n",
        "    def sigma(self):\n",
        "        return torch.log1p(torch.exp(self.rho))\n",
        "    \n",
        "    def sample(self):\n",
        "        epsilon = self.normal.sample(self.rho.size()).to(DEVICE)\n",
        "        return self.mu + self.sigma * epsilon\n",
        "    \n",
        "    def log_prob(self, input):\n",
        "        return (-math.log(math.sqrt(2 * math.pi))\n",
        "                - torch.log(self.sigma)\n",
        "                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:43:52.454252Z",
          "iopub.execute_input": "2021-09-27T11:43:52.454765Z",
          "iopub.status.idle": "2021-09-27T11:43:52.464065Z",
          "shell.execute_reply.started": "2021-09-27T11:43:52.454736Z",
          "shell.execute_reply": "2021-09-27T11:43:52.462216Z"
        },
        "trusted": true,
        "id": "E8vMogOojJg0"
      },
      "source": [
        "class ScaleMixtureGaussian(object):\n",
        "    def __init__(self, pi, sigma1, sigma2):\n",
        "        super().__init__()\n",
        "        self.pi = pi\n",
        "        self.sigma1 = sigma1\n",
        "        self.sigma2 = sigma2\n",
        "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
        "        self.gaussian2 = torch.distributions.Normal(0,sigma2)\n",
        "    \n",
        "    def log_prob(self, input):\n",
        "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
        "        prob2 = torch.exp(self.gaussian2.log_prob(input))\n",
        "        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:43:52.465558Z",
          "iopub.execute_input": "2021-09-27T11:43:52.466086Z",
          "iopub.status.idle": "2021-09-27T11:44:06.372581Z",
          "shell.execute_reply.started": "2021-09-27T11:43:52.466045Z",
          "shell.execute_reply": "2021-09-27T11:44:06.371543Z"
        },
        "trusted": true,
        "id": "qRu3AZnEjJg1"
      },
      "source": [
        "PI = 0.5\n",
        "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
        "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
        "\n",
        "def visualize_scale_mixture_components():\n",
        "    def show_lines():\n",
        "        pass\n",
        "    mix = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "    normal_1 = torch.distributions.Normal(0, SIGMA_1)\n",
        "    normal_2 = torch.distributions.Normal(0, SIGMA_2)\n",
        "    x_points = np.linspace(-5,5,10000)\n",
        "    d1 = np.array([torch.exp(normal_1.log_prob(float(c))) for c in x_points])\n",
        "    d2 = np.array([torch.exp(normal_2.log_prob(float(c))) for c in x_points])\n",
        "    d3 = np.array([torch.exp(mix.log_prob(float(c))) for c in x_points])\n",
        "    plt.subplots(1,3,figsize=(14,4))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.plot(x_points,d2,color=\"g\")\n",
        "    plt.plot(x_points,d3,color=\"r\")\n",
        "    plt.plot(x_points,d1,color=\"b\")\n",
        "    plt.legend([\"sigma2\", \"mix\", \"sigma1\"])\n",
        "    plt.ylim(0,0.5)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.plot(x_points,d1,color=\"b\")\n",
        "    plt.plot(x_points,d2,color=\"g\")\n",
        "    plt.plot(x_points,d3,color=\"r\")\n",
        "    plt.legend([\"sigma1\", \"sigma2\", \"mix\"])\n",
        "    plt.ylim(0,160)\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.plot(x_points,d2,color=\"g\")\n",
        "    plt.plot(x_points,d3,color=\"r\")\n",
        "    plt.plot(x_points,d1,color=\"b\")\n",
        "    plt.legend([\"sigma2\", \"mix\", \"sigma1\"])\n",
        "    plt.ylim(0,80)\n",
        "    \n",
        "visualize_scale_mixture_components()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:06.374003Z",
          "iopub.execute_input": "2021-09-27T11:44:06.375068Z",
          "iopub.status.idle": "2021-09-27T11:44:06.389429Z",
          "shell.execute_reply.started": "2021-09-27T11:44:06.374987Z",
          "shell.execute_reply": "2021-09-27T11:44:06.388188Z"
        },
        "trusted": true,
        "id": "kWfZzHU8jJg3"
      },
      "source": [
        "class BayesianLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        # Weight parameters\n",
        "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
        "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5,-4))\n",
        "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
        "        # Bias parameters\n",
        "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
        "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))\n",
        "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
        "        # Prior distributions\n",
        "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.log_prior = 0\n",
        "        self.log_variational_posterior = 0\n",
        "\n",
        "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
        "        if self.training or sample:\n",
        "            weight = self.weight.sample()\n",
        "            bias = self.bias.sample()\n",
        "        else:\n",
        "            weight = self.weight.mu\n",
        "            bias = self.bias.mu\n",
        "        if self.training or calculate_log_probs:\n",
        "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
        "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
        "        else:\n",
        "            self.log_prior, self.log_variational_posterior = 0, 0\n",
        "\n",
        "        return F.linear(input, weight, bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:06.393278Z",
          "iopub.execute_input": "2021-09-27T11:44:06.393691Z",
          "iopub.status.idle": "2021-09-27T11:44:06.428322Z",
          "shell.execute_reply.started": "2021-09-27T11:44:06.393651Z",
          "shell.execute_reply": "2021-09-27T11:44:06.427479Z"
        },
        "trusted": true,
        "id": "zDi7gYW2jJg4"
      },
      "source": [
        "class BayesianNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = BayesianLinear(28*28, 400)\n",
        "        self.l2 = BayesianLinear(400, 400)\n",
        "        self.l3 = BayesianLinear(400, 10)\n",
        "    \n",
        "    def forward(self, x, sample=False):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.l1(x, sample))\n",
        "        x = F.relu(self.l2(x, sample))\n",
        "        x = F.log_softmax(self.l3(x, sample), dim=1)\n",
        "        return x\n",
        "    \n",
        "    def log_prior(self):\n",
        "        return self.l1.log_prior \\\n",
        "               + self.l2.log_prior \\\n",
        "               + self.l3.log_prior\n",
        "    \n",
        "    def log_variational_posterior(self):\n",
        "        return self.l1.log_variational_posterior \\\n",
        "               + self.l2.log_variational_posterior \\\n",
        "               + self.l3.log_variational_posterior\n",
        "    \n",
        "    def sample_elbo(self, input, target, samples=SAMPLES):\n",
        "        outputs = torch.zeros(samples, BATCH_SIZE, CLASSES).to(DEVICE)\n",
        "        log_priors = torch.zeros(samples).to(DEVICE)\n",
        "        log_variational_posteriors = torch.zeros(samples).to(DEVICE)\n",
        "        for i in range(samples):\n",
        "            outputs[i] = self(input, sample=True)\n",
        "            log_priors[i] = self.log_prior()\n",
        "            log_variational_posteriors[i] = self.log_variational_posterior()\n",
        "        log_prior = log_priors.mean()\n",
        "        log_variational_posterior = log_variational_posteriors.mean()\n",
        "        negative_log_likelihood = F.nll_loss(outputs.mean(0), target, size_average=False)\n",
        "        loss = (log_variational_posterior - log_prior)/NUM_BATCHES + negative_log_likelihood\n",
        "        return loss, log_prior, log_variational_posterior, negative_log_likelihood\n",
        "\n",
        "net = BayesianNetwork().to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:06.429912Z",
          "iopub.execute_input": "2021-09-27T11:44:06.430216Z",
          "iopub.status.idle": "2021-09-27T11:44:06.441321Z",
          "shell.execute_reply.started": "2021-09-27T11:44:06.430180Z",
          "shell.execute_reply": "2021-09-27T11:44:06.440160Z"
        },
        "trusted": true,
        "id": "uQqWF_uGjJg5"
      },
      "source": [
        "def write_weight_histograms(epoch):\n",
        "    writer.add_histogram('histogram/w1_mu', net.l1.weight_mu,epoch)\n",
        "    writer.add_histogram('histogram/w1_rho', net.l1.weight_rho,epoch)\n",
        "    writer.add_histogram('histogram/w2_mu', net.l2.weight_mu,epoch)\n",
        "    writer.add_histogram('histogram/w2_rho', net.l2.weight_rho,epoch)\n",
        "    writer.add_histogram('histogram/w3_mu', net.l3.weight_mu,epoch)\n",
        "    writer.add_histogram('histogram/w3_rho', net.l3.weight_rho,epoch)\n",
        "    writer.add_histogram('histogram/b1_mu', net.l1.bias_mu,epoch)\n",
        "    writer.add_histogram('histogram/b1_rho', net.l1.bias_rho,epoch)\n",
        "    writer.add_histogram('histogram/b2_mu', net.l2.bias_mu,epoch)\n",
        "    writer.add_histogram('histogram/b2_rho', net.l2.bias_rho,epoch)\n",
        "    writer.add_histogram('histogram/b3_mu', net.l3.bias_mu,epoch)\n",
        "    writer.add_histogram('histogram/b3_rho', net.l3.bias_rho,epoch)\n",
        "\n",
        "def write_loss_scalars(epoch, batch_idx, loss, log_prior, log_variational_posterior, negative_log_likelihood):\n",
        "    writer.add_scalar('logs/loss', loss, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/complexity_cost', log_variational_posterior-log_prior, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/log_prior', log_prior, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/log_variational_posterior', log_variational_posterior, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/negative_log_likelihood', negative_log_likelihood, epoch*NUM_BATCHES+batch_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:06.443278Z",
          "iopub.execute_input": "2021-09-27T11:44:06.443881Z",
          "iopub.status.idle": "2021-09-27T11:44:06.456182Z",
          "shell.execute_reply.started": "2021-09-27T11:44:06.443812Z",
          "shell.execute_reply": "2021-09-27T11:44:06.455103Z"
        },
        "trusted": true,
        "id": "EwafxVKtjJg6"
      },
      "source": [
        "def train(net, optimizer, epoch):\n",
        "    net.train()\n",
        "    if epoch == 0: # write initial distributions\n",
        "        write_weight_histograms(epoch)\n",
        "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        net.zero_grad()\n",
        "        loss, log_prior, log_variational_posterior, negative_log_likelihood = net.sample_elbo(data, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        write_loss_scalars(epoch, batch_idx, loss, log_prior, log_variational_posterior, negative_log_likelihood)\n",
        "    write_weight_histograms(epoch+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:06.457577Z",
          "iopub.execute_input": "2021-09-27T11:44:06.457902Z",
          "iopub.status.idle": "2021-09-27T11:44:34.612652Z",
          "shell.execute_reply.started": "2021-09-27T11:44:06.457859Z",
          "shell.execute_reply": "2021-09-27T11:44:34.610691Z"
        },
        "trusted": true,
        "id": "5o8LGZiMjJg7"
      },
      "source": [
        "optimizer = optim.Adam(net.parameters())\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    train(net, optimizer, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:34.614251Z",
          "iopub.status.idle": "2021-09-27T11:44:34.615184Z",
          "shell.execute_reply.started": "2021-09-27T11:44:34.614804Z",
          "shell.execute_reply": "2021-09-27T11:44:34.614836Z"
        },
        "trusted": true,
        "id": "WQGFxs6LjJg8"
      },
      "source": [
        "def test_ensemble():\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    corrects = np.zeros(TEST_SAMPLES+1, dtype=int)\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            outputs = torch.zeros(TEST_SAMPLES+1, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
        "            for i in range(TEST_SAMPLES):\n",
        "                outputs[i] = net(data, sample=True)\n",
        "            outputs[TEST_SAMPLES] = net(data, sample=False)\n",
        "            output = outputs.mean(0)\n",
        "            preds = preds = outputs.max(2, keepdim=True)[1]\n",
        "            pred = output.max(1, keepdim=True)[1] # index of max log-probability\n",
        "            corrects += preds.eq(target.view_as(pred)).sum(dim=1).squeeze().cpu().numpy()\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    for index, num in enumerate(corrects):\n",
        "        if index < TEST_SAMPLES:\n",
        "            print('Component {} Accuracy: {}/{}'.format(index, num, TEST_SIZE))\n",
        "        else:\n",
        "            print('Posterior Mean Accuracy: {}/{}'.format(num, TEST_SIZE))\n",
        "    print('Ensemble Accuracy: {}/{}'.format(correct, TEST_SIZE))\n",
        "\n",
        "test_ensemble()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:34.617380Z",
          "iopub.status.idle": "2021-09-27T11:44:34.618230Z",
          "shell.execute_reply.started": "2021-09-27T11:44:34.617916Z",
          "shell.execute_reply": "2021-09-27T11:44:34.617942Z"
        },
        "trusted": true,
        "id": "XtFDT86BjJg8"
      },
      "source": [
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:34.620185Z",
          "iopub.status.idle": "2021-09-27T11:44:34.620770Z",
          "shell.execute_reply.started": "2021-09-27T11:44:34.620412Z",
          "shell.execute_reply": "2021-09-27T11:44:34.620437Z"
        },
        "trusted": true,
        "id": "udfUcc-cjJg9"
      },
      "source": [
        "fmnist_sample = iter(test_loader).next()\n",
        "fmnist_sample[0] = fmnist_sample[0].to(DEVICE)\n",
        "print(fmnist_sample[1])\n",
        "sns.set_style(\"dark\")\n",
        "show(make_grid(fmnist_sample[0].cpu()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:34.622729Z",
          "iopub.status.idle": "2021-09-27T11:44:34.623257Z",
          "shell.execute_reply.started": "2021-09-27T11:44:34.622983Z",
          "shell.execute_reply": "2021-09-27T11:44:34.623008Z"
        },
        "trusted": true,
        "id": "rno734l8jJg-"
      },
      "source": [
        "net.eval()\n",
        "fmnist_outputs = net(fmnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy()\n",
        "for _ in range(99):\n",
        "    fmnist_outputs = np.append(fmnist_outputs, net(fmnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy(), axis=1)\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.subplots(5,1,figsize=(10,4))\n",
        "for i in range(5):\n",
        "    plt.subplot(5,1,i+1)\n",
        "    plt.ylim(0,100)\n",
        "    plt.xlabel(\"Categories\")\n",
        "    plt.xticks(range(10), [\"Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"])\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.yticks(range(50,101,50))\n",
        "    plt.hist(fmnist_outputs[i], np.arange(-0.5, 10, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:34.624670Z",
          "iopub.status.idle": "2021-09-27T11:44:34.626078Z",
          "shell.execute_reply.started": "2021-09-27T11:44:34.625752Z",
          "shell.execute_reply": "2021-09-27T11:44:34.625781Z"
        },
        "trusted": true,
        "id": "jeklHuCujJg_"
      },
      "source": [
        "mnist_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist', train=False, download=True, transform=transforms.ToTensor()), batch_size=5, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:34.627845Z",
          "iopub.status.idle": "2021-09-27T11:44:34.628380Z",
          "shell.execute_reply.started": "2021-09-27T11:44:34.628103Z",
          "shell.execute_reply": "2021-09-27T11:44:34.628127Z"
        },
        "trusted": true,
        "id": "lYBWWPITjJg_"
      },
      "source": [
        "mnist_sample = iter(mnist_loader).next()\n",
        "mnist_sample[0] = mnist_sample[0].to(DEVICE)\n",
        "print(mnist_sample[1])\n",
        "sns.set_style(\"dark\")\n",
        "show(make_grid(mnist_sample[0].cpu()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-27T11:44:34.630239Z",
          "iopub.status.idle": "2021-09-27T11:44:34.631096Z",
          "shell.execute_reply.started": "2021-09-27T11:44:34.630770Z",
          "shell.execute_reply": "2021-09-27T11:44:34.630796Z"
        },
        "trusted": true,
        "id": "JHkZwstujJhA"
      },
      "source": [
        "net.eval()\n",
        "mnist_outputs = net(mnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy()\n",
        "for _ in range(99):\n",
        "    mnist_outputs = np.append(mnist_outputs, net(mnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy(), axis=1)\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.subplots(5,1,figsize=(10,4))\n",
        "for i in range(5):\n",
        "    plt.subplot(5,1,i+1)\n",
        "    plt.ylim(0,100)\n",
        "    plt.xlabel(\"Categories\")\n",
        "    plt.xticks(range(10), [\"Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"])\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.yticks(range(50,101,50))\n",
        "    plt.hist(mnist_outputs[i], np.arange(-0.5, 10, 1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}